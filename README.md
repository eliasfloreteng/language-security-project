# Python Pickle Module Security Vulnerability Demonstration

## Background

Python's `pickle` module is used for serializing and deserializing Python objects. "Pickling" converts a Python object hierarchy into a byte stream, and "unpickling" converts that byte stream back into an object hierarchy. While convenient for persisting data or inter-process communication, the `pickle` module is explicitly documented as **not secure** for untrusted data. Maliciously crafted pickle data can lead to arbitrary code execution during the unpickling process. This vulnerability arises because the pickle byte stream contains opcodes that are executed sequentially upon deserialization, including the ability to call arbitrary functions with supplied arguments via the `__reduce__` method.

## Goal

This project aims to explore the security risks associated with Python's `pickle` library. Specifically, we aim to demonstrate how manipulated pickled files can lead to arbitrary code execution. We will also investigate and propose mitigation strategies or alternatives to safely deserialize Python objects.

The project directly relates to the Language-Based Security course, as it investigates language features (serialization and deserialization) and their exploitation in Python, a mainstream programming language. By focusing on the pickle module, we will examine how language design and unsafe library APIs contribute to common vulnerabilities. This work will reinforce core course concepts such as secure API design and deserialization attacks.

## Method

To demonstrate the attack, we will create two Python scripts:

1.  `vulnerable_app.py`: This script will simulate a simple application that loads a pickled object from a file. It represents a common scenario where an application might deserialize data without proper validation.
2.  `exploit.py`: This script will craft a malicious pickled payload. The payload will leverage the `__reduce__` method to execute a system command (`echo Malicious code executed!`) when unpickled.
    The `__reduce__` method is a special method in Python that allows objects to define how they should be pickled. When an object implementing `__reduce__` is pickled, this method is called, and its return value (a string or a tuple) dictates how the object is represented in the pickle stream. If a tuple is returned, its first element is a callable object, and the second is a tuple of arguments for that callable. During unpickling, this callable is invoked with the provided arguments. Attackers can abuse this mechanism by making `__reduce__` return a dangerous callable (like `os.system` or `eval`) and a malicious command as its argument, leading to arbitrary code execution.
3.  `run_attack.py`: This script will orchestrate the attack by first pickling a benign object, then demonstrating how an attacker could replace it with a malicious payload, and finally showing the vulnerable application unpickling the malicious data.

This vulnerability can manifest as an **offline tampering attack** where an attacker modifies a pickled file stored on disk. If the application later loads this tampered file, the malicious code executes. In the context of web applications, this can be even more dangerous, potentially leading to Remote Code Execution (RCE) if a web endpoint deserializes untrusted data directly from user input. Furthermore, this vulnerability poses a significant risk in **supply-chain attacks**, where a legitimate GitHub repository or a third-party library might inadvertently contain or use a maliciously crafted pickle file, compromising systems that import or process it.

## Results

When `vulnerable_app.py` attempts to unpickle the malicious data generated by `exploit.py`, the system command embedded within the payload will be executed. This demonstrates the arbitrary code execution vulnerability inherent in unpickling untrusted data. The output "Malicious code executed!" will confirm the successful execution of the injected command, highlighting how easily an attacker can achieve control over the system by manipulating serialized data. This successful demonstration underscores the critical importance of validating and securing deserialization processes, especially when dealing with data from untrusted sources.

## Mitigation Strategies

To safely handle serialization and deserialization in Python, it is crucial to avoid `pickle` when dealing with untrusted data. Safer alternatives and practices include:

- **Using Data-Only Serialization Formats**: For untrusted data, prefer formats like JSON (JavaScript Object Notation), YAML, or MessagePack. These formats are designed for data interchange and do not inherently support arbitrary code execution during deserialization.
  - **JSON**: Lightweight, human-readable, and language-agnostic. Python's built-in `json` module is suitable for this.
  - **MessagePack**: A binary serialization format that is more compact and faster than JSON, suitable for performance-critical applications.
  - **Note on PyYAML and jsonpickle**: While JSON and YAML are generally safer, it's important to note that certain libraries like `PyYAML` (when using `yaml.load` without specifying a safe loader) and `jsonpickle` can also be vulnerable to similar deserialization attacks if not used carefully, as they might allow deserialization of arbitrary Python objects or execution of code. Always ensure you are using safe loading functions (e.g., `yaml.safe_load` for PyYAML) and understand the security implications of any serialization library.
- **Message Authentication Codes (MAC)**: If you must use `pickle` for trusted data (e.g., internal communication where data integrity is paramount), generate a cryptographic signature (e.g., using `hmac`) for the pickled data. The receiver can then validate this signature before unpickling to ensure the data has not been tampered with. This protects against offline tampering but does not mitigate vulnerabilities if the original source of the pickled data is compromised.
- **Restricting Globals**: For advanced use cases where `pickle` is unavoidable, you can customize `Unpickler.find_class` to restrict which classes and functions can be imported during unpickling. This acts as a whitelist, preventing the deserialization of dangerous objects. However, this is complex and prone to error, as it requires a deep understanding of all possible "gadgets" that could be exploited.

## References

- [Python `pickle` module documentation](https://docs.python.org/3/library/pickle.html)
- [Exploiting Python pickles - David Hamann](https://davidhamann.de/2020/04/05/exploiting-python-pickle/)
- [Unsafe Deserialization in Python | SecureFlag Security Knowledge Base](https://knowledge-base.secureflag.com/vulnerabilities/unsafe_deserialization/unsafe_deserialization_python.html)
- [The ultimate guide to Python pickle | Snyk](https://snyk.io/blog/guide-to-python-pickle/)
- [Python Pickle Risks and Safer Serialization Alternatives | ArjanCodes](https://arjancodes.com/blog/python-pickle-module-security-risks-and-safer-alternatives/)
- [OWASP Deserialization Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Deserialization_Cheat_Sheet.html)
